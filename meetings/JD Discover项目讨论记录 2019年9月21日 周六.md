<h2><center>JD Discover项目讨论记录 2019年9月21日 周六</center></h2>
[TOC]

***

### 一、项目目标

项目主要想通过对UTC的实习历史记录进行文本挖掘，发现对找实习有用的信息，并且希望能优化查询的用户接口，提供更多的JD推荐和匹配功能。

***

###  二、项目进行的大体步骤

#### 1、数据收集

为了能够实现我们的文本挖掘需求，我们需要爬取以下两部分主要内容：

- UTC历年的实习记录，包括年份，学期，类型（TN09/10），专业（大类和小专业），sujet描述，公司名称，公司地址等。注意：不可爬取实习对应的个人信息（étudiant, tuteur, suiveur）
- UTC课程介绍（暂时不用考虑）。

#### 2、初步数据清洗和存储

- 处理编码问题（PyCharm，UTF-8）
- 将英语和法语的描述分开处理
- 清洗网页标签，保留我们需要的部分即可，并进行结构化的存储

#### 3、构建文本特征

- BOW(bag of word)
- TF-IDF
  - 分词
  - 去停用词
  - Lemmatisation/Steaming
- One-Hot编码
- Word Embedding (如word2vec)

#### 4、数理统计和数据可视化

针对构建好的文本特征我们可以进行以下几个方面或者更多的统计学分析。

- 统计每个学科中常用技术的应用情况 (需要各学课的技术词库）
- 统计和UTC合作的公司情况：地理位置，合作持续性等
- 其他统计

#### 5、NLP领域探索

- 以此语料库为样本进行文档分类训练。希望训练得到的模型能够应用于其他求职网站的JD分类(如Indeed，LinkedIn等)
- 文本聚类，可能可以发现学课交叉的情况
- 关键词提取，主要是想要各个专业的主要应用技术
- LDA(Latent Dirchlet Allocation) 和 HMM(Hidden Markov Model) 模型探索，了解此模型的作用，背后的数学原理和工程实现
- 基于关键词的文本生成 (GAN)
***
### 三、To do list

项目开始第一周（2019/09/22 - 2019/09/28），我们主要是进行一些准备工作，知识学习和数据的爬取工作，具体如下：

1. 完成代码仓库的构建，添加小组成员成为co-contributor，@张海飞
2. 爬取数据并实现结构化存储（Json和XML），@汪宇辉
3. 学习BOW，TF-IDF，One-Hot编码，word2vec，@所有成员

***